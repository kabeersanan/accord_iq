import os
import uuid
import json
from typing import List, Optional
from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Directory setup
INDEX_DIR = os.getenv("INDEX_DIR", os.path.join(os.path.dirname(__file__), "indexes"))
os.makedirs(INDEX_DIR, exist_ok=True)

# Config paths
METADATA_PATH = os.path.join(INDEX_DIR, "id_map.json")
FAISS_INDEX_PATH = os.path.join(INDEX_DIR, "faiss.index")
EMBED_DIM = 384  # must match your embedding model

# FastAPI init
app = FastAPI(title="RAG PDF Chat")

# Enable CORS for local frontend testing
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# Utils imports
from utils.extractor import extract_text_from_pdf
from utils.chunker import chunk_text
from utils.embedder import Embedder
from utils.vectorstore_faiss import FaissVectorStore
from utils.generator_gemini import GeminiGenerator

# Initialize core components
embedder = Embedder()
generator = GeminiGenerator()
vector_store = FaissVectorStore(dim=EMBED_DIM)

# Load persisted FAISS index and metadata
if os.path.exists(METADATA_PATH):
    try:
        with open(METADATA_PATH, "r", encoding="utf-8") as f:
            vector_store.id_map = json.load(f)
        if os.path.exists(FAISS_INDEX_PATH):
            import faiss
            vector_store.index = faiss.read_index(FAISS_INDEX_PATH)
            print("‚úÖ Loaded FAISS index and metadata from disk")
    except Exception as e:
        print("‚ö†Ô∏è Failed to load persisted index:", e)


def persist_index_and_map():
    """Save FAISS index and id_map to disk."""
    try:
        import faiss
        faiss.write_index(vector_store.index, FAISS_INDEX_PATH)
        with open(METADATA_PATH, "w", encoding="utf-8") as f:
            json.dump(vector_store.id_map, f, ensure_ascii=False, indent=2)
        print("‚úÖ Persisted FAISS index and metadata")
    except Exception as e:
        print("‚ùå Error persisting index:", e)


# -------------------------------
# üìÑ PDF Upload Endpoint
# -------------------------------
@app.post("/upload_pdf")
async def upload_pdf(file: UploadFile = File(...)):
    """Upload a PDF, extract text, chunk, embed, and add to FAISS."""
    if not file.filename.lower().endswith(".pdf"):
        raise HTTPException(status_code=400, detail="Only PDF files are supported.")

    # Generate unique file_id
    file_id = str(uuid.uuid4())
    tmp_path = os.path.join(INDEX_DIR, f"{file_id}.pdf")

    # Save uploaded file temporarily
    with open(tmp_path, "wb") as f:
        content = await file.read()
        f.write(content)

    # Extract text per page
    pages_text = extract_text_from_pdf(tmp_path)
    pages = [{"page": i + 1, "text": p} for i, p in enumerate(pages_text)]

    # Chunk the text
    full_text = " ".join(pages_text)
    chunks_texts = chunk_text(full_text)

    chunks = []
    for i, t in enumerate(chunks_texts):
        cid = f"{file_id}_c{i}"
        chunks.append({
            "id": cid,
            "text": t,
            "metadata": {"file_id": file_id, "chunk_index": i}
        })

    # Create embeddings and add to FAISS
    chunks = embedder.create_embeddings(chunks)
    vector_store.add_embeddings(chunks)
    persist_index_and_map()

    return JSONResponse({
        "file_id": file_id,
        "num_pages": len(pages_text),
        "num_chunks": len(chunks_texts)
    })


# -------------------------------
# üí¨ Ask Question Endpoint
# -------------------------------
class AskRequest(BaseModel):
    question: str
    file_id: Optional[str] = None
    top_k: Optional[int] = 3


@app.post("/ask")
async def ask(req: AskRequest):
    """
    Accepts JSON body:
    {
        "question": "your question",
        "file_id": "optional-file-id",
        "top_k": 3
    }
    """
    question = req.question
    file_id = req.file_id
    top_k = req.top_k or 3

    if not question or question.strip() == "":
        raise HTTPException(status_code=400, detail="question cannot be empty")

    # Embed the question
    q_vec = embedder.embed_query(question)
    print("DEBUG q_vec_len =", len(q_vec))

    # --- Normalize query for cosine/IP FAISS ---
    import numpy as np
    q_arr = np.array(q_vec, dtype=np.float32).reshape(1, -1)
    norm = float(np.linalg.norm(q_arr))
    if norm != 0.0:
        q_arr = q_arr / norm
    q_arr_np = q_arr.flatten().astype('float32')

    print(f"[DEBUG] normalized q_vec len={len(q_arr_np)} (norm was {norm:.4f})")

    # Perform search
    debug_top_k = max(10, top_k)
    results = vector_store.search(q_arr_np, top_k=debug_top_k)
    print(f"[DEBUG] search returned {len(results)} results (top_k={debug_top_k})")

    # Optional: restrict by file_id
    if file_id:
        results = [r for r in results if r.get("metadata", {}).get("file_id") == file_id]
        if not results:
            return JSONResponse({
                "answer": None,
                "retrieved": [],
                "note": "no chunks for that file_id"
            }, status_code=200)

    # Generate answer with Gemini
    answer_text = generator.generate_answer(question, results)

    return {"answer": answer_text, "retrieved": results}


# -------------------------------
# üß† Debug Info Endpoint
# -------------------------------
@app.get("/debug/index_info")
def debug_index_info():
    try:
        idx = getattr(vector_store, "index", None)
        id_map = getattr(vector_store, "id_map", {})
        info = {
            "index_exists": idx is not None,
            "id_map_size": len(id_map),
        }
        try:
            import faiss
            info["ntotal"] = int(idx.ntotal) if idx is not None else 0
        except Exception:
            info["ntotal"] = None
        info["sample_ids"] = list(id_map.keys())[:10]
        return info
    except Exception as e:
        return {"error": str(e)}


@app.get("/")
def root():
    return {"status": "ok", "message": "RAG PDF Chat backend is running"}
